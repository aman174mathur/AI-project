
Job Title: Data Engineer
Location: Bangalore, India (Hybrid)
Experience: 2-5 years
Employment Type: Full-Time

About the Role:
We are seeking a skilled and motivated Data Engineer to design, develop, and maintain scalable data pipelines. 
You will collaborate with data scientists, analysts, and software engineers to ensure reliable and efficient data access across the organization.

Key Responsibilities:
- Design and build efficient, scalable, and reliable data pipelines using tools like Apache Spark, Kafka, and Airflow.
- Develop ETL processes to ingest, transform, and store structured and unstructured data.
- Work with cloud platforms like AWS, GCP, or Azure to manage data storage and compute infrastructure.
- Collaborate with cross-functional teams to understand data requirements and deliver solutions.
- Monitor and optimize the performance of data workflows.
- Ensure data quality and consistency across various data sources.

Required Skills and Qualifications:
- Bachelorâ€™s degree in Computer Science, Engineering, or related field.
- Proficiency in SQL, Python, and one or more data pipeline tools (e.g., Apache Spark, Airflow).
- Experience with relational databases (PostgreSQL, MySQL) and NoSQL databases (MongoDB, Cassandra).
- Familiarity with data warehousing concepts (e.g., Snowflake, Redshift, BigQuery).
- Experience working with cloud platforms (AWS/GCP/Azure).
- Strong understanding of data modeling and data architecture.

Preferred Qualifications:
- Knowledge of DevOps tools like Docker, Kubernetes, and Terraform.
- Hands-on experience with real-time data processing tools like Kafka or Flink.
- Familiarity with CI/CD pipelines and version control (Git).

What We Offer:
- Competitive salary and performance-based bonuses.
- Flexible working hours and hybrid remote work.
- Learning and development budget for certifications, courses, and events.
- Work on impactful data projects with modern technologies.
